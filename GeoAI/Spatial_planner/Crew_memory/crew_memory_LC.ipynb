{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc185fb-67e8-4938-b946-832d6c9c6ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda8f199-821d-4bd5-a5fa-7bce801439d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29e0f93b-79d7-4aec-b154-a703235b6297",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PtExampleSelector(BaseExampleSelector):\n",
    "    \"\"\"\n",
    "    LangChain-compatible ExampleSelector that uses a precomputed torch tensor of embeddings (.pt),\n",
    "    or computes them with HuggingFaceEmbeddings if absent.\n",
    "    Each example must contain an \"instruction\" field used as the searchable text.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        examples: List[Dict],\n",
    "        embeddings_file: Optional[str] = None,\n",
    "        model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        instruction_key: str = \"instruction\",\n",
    "        device: Optional[str] = None,  # \"cpu\" | \"cuda\" | None (auto)\n",
    "    ):\n",
    "        self.examples = examples\n",
    "        self.instruction_key = instruction_key\n",
    "        self.instructions = [ex.get(self.instruction_key, \"\") for ex in self.examples]\n",
    "\n",
    "        # Embedding model (LangChain wrapper around sentence-transformers)\n",
    "        self.embed = HuggingFaceEmbeddings(model_name=model_name)\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.embeddings_path = Path(embeddings_file) if embeddings_file else None\n",
    "        self.emb_t: Optional[torch.Tensor] = None  # (N, d)\n",
    "\n",
    "        self._load_or_build_embeddings()\n",
    "\n",
    "    def _load_or_build_embeddings(self):\n",
    "        # Try loading .pt\n",
    "        if self.embeddings_path and self.embeddings_path.exists():\n",
    "            self.emb_t = torch.load(self.embeddings_path, map_location=self.device)\n",
    "            if not isinstance(self.emb_t, torch.Tensor):\n",
    "                self.emb_t = torch.tensor(self.emb_t, device=self.device)\n",
    "        else:\n",
    "            # Compute via LangChain wrapper (returns list[list[float]])\n",
    "            if len(self.instructions) == 0:\n",
    "                self.emb_t = torch.empty((0, 0), device=self.device)\n",
    "                return\n",
    "            vecs = self.embed.embed_documents(self.instructions)  # List[List[float]]\n",
    "            self.emb_t = torch.tensor(np.array(vecs), device=self.device, dtype=torch.float32)\n",
    "            if self.embeddings_path:\n",
    "                torch.save(self.emb_t, self.embeddings_path)\n",
    "\n",
    "        # Normalize once for cosine similarity\n",
    "        if self.emb_t.numel() > 0:\n",
    "            self.emb_t = F.normalize(self.emb_t, dim=1)\n",
    "\n",
    "    # ---- BaseExampleSelector API ----\n",
    "    def add_example(self, example: Dict) -> None:\n",
    "        \"\"\"Append a new example and update embeddings on the fly.\"\"\"\n",
    "        self.examples.append(example)\n",
    "        text = example.get(self.instruction_key, \"\")\n",
    "        if not text:\n",
    "            # still keep it, but skip embedding\n",
    "            return\n",
    "        v = self.embed.embed_query(text)\n",
    "        v_t = torch.tensor(np.array(v), device=self.device, dtype=torch.float32).unsqueeze(0)\n",
    "        v_t = F.normalize(v_t, dim=1)\n",
    "\n",
    "        if self.emb_t is None or self.emb_t.numel() == 0:\n",
    "            self.emb_t = v_t\n",
    "        else:\n",
    "            self.emb_t = torch.cat([self.emb_t, v_t], dim=0)\n",
    "\n",
    "        self.instructions.append(text)\n",
    "        # Persist if path was provided\n",
    "        if self.embeddings_path:\n",
    "            torch.save(self.emb_t, self.embeddings_path)\n",
    "\n",
    "    def select_examples(self, input_variables: Dict) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        LangChain calls this with your input variables.\n",
    "        By convention weâ€™ll look for 'user_prompt' first, else any single string value.\n",
    "        \"\"\"\n",
    "        if not self.examples:\n",
    "            return []\n",
    "\n",
    "        query = input_variables.get(\"user_prompt\")\n",
    "        if query is None:\n",
    "            # Pick the first str in the dict as query (fallback)\n",
    "            for v in input_variables.values():\n",
    "                if isinstance(v, str) and v.strip():\n",
    "                    query = v\n",
    "                    break\n",
    "        if not query:\n",
    "            # No query -> return first few examples\n",
    "            return self.examples[: min(3, len(self.examples))]\n",
    "\n",
    "        # Embed query and cosine-sim against stored embeddings\n",
    "        q = self.embed.embed_query(query)\n",
    "        q_t = torch.tensor(np.array(q), device=self.device, dtype=torch.float32).unsqueeze(0)\n",
    "        q_t = F.normalize(q_t, dim=1)\n",
    "\n",
    "        # Shapes: q_t = (1, d), emb_t = (N, d)\n",
    "        sims = (q_t @ self.emb_t.T).squeeze(0)  # cosine similarity after normalization\n",
    "        k = min(3, sims.shape[0])  # default top-3 for selector\n",
    "        topk = torch.topk(sims, k=k).indices.tolist()\n",
    "        return [self.examples[i] for i in topk]\n",
    "\n",
    "    # ---- Convenience methods (not required by BaseExampleSelector) ----\n",
    "    def top_k(self, query: str, k: int = 3) -> List[Dict]:\n",
    "        if not self.examples:\n",
    "            return []\n",
    "        q = self.embed.embed_query(query)\n",
    "        q_t = torch.tensor(np.array(q), device=self.device, dtype=torch.float32).unsqueeze(0)\n",
    "        q_t = F.normalize(q_t, dim=1)\n",
    "        sims = (q_t @ self.emb_t.T).squeeze(0)\n",
    "        k = min(k, sims.shape[0])\n",
    "        idxs = torch.topk(sims, k=k).indices.tolist()\n",
    "        return [self.examples[i] for i in idxs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b634b58e-f2cb-41eb-907f-3f23b9c37f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrewMemoryLC:\n",
    "    \"\"\"\n",
    "    High-level wrapper so you can keep calling .top_k() / .get_similar_examples()\n",
    "    and also get a LangChain-compatible FewShotPromptTemplate.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        memory_file: str,\n",
    "        embeddings_file: Optional[str] = None,\n",
    "        model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        instruction_key: str = \"instruction\",\n",
    "        device: Optional[str] = None,\n",
    "    ):\n",
    "        self.memory_path = Path(memory_file)\n",
    "        if not self.memory_path.exists():\n",
    "            raise FileNotFoundError(f\"Memory file not found: {self.memory_path}\")\n",
    "\n",
    "        self.examples: List[Dict] = json.loads(self.memory_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "        self.selector = PtExampleSelector(\n",
    "            examples=self.examples,\n",
    "            embeddings_file=embeddings_file,\n",
    "            model_name=model_name,\n",
    "            instruction_key=instruction_key,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    # ---- Backwards-friendly API ----\n",
    "    def get_similar_examples(self, new_instruction: str, top_k: int = 2) -> List[Dict]:\n",
    "        return self.selector.top_k(new_instruction, k=top_k)\n",
    "\n",
    "    def top_k(self, query: str, k: int = 3) -> List[Dict]:\n",
    "        return self.selector.top_k(query, k=k)\n",
    "\n",
    "    def add_example(self, example: Dict) -> None:\n",
    "        \"\"\"Append to JSON + update embedding + persist JSON.\"\"\"\n",
    "        self.selector.add_example(example)\n",
    "        self.examples.append(example)\n",
    "        self.memory_path.write_text(json.dumps(self.examples, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    # ---- LangChain FewShot integration ----\n",
    "    def make_fewshot_prompt(\n",
    "        self,\n",
    "        example_prompt: PromptTemplate,\n",
    "        suffix: str,\n",
    "        input_variables: List[str],\n",
    "        k_default: int = 3,\n",
    "    ) -> FewShotPromptTemplate:\n",
    "        \"\"\"\n",
    "        Returns a FewShotPromptTemplate that calls our selector.\n",
    "        LangChain will use select_examples() under the hood.\n",
    "        \"\"\"\n",
    "        # Note: k_default is controlled inside select_examples (top-3). You can change that by editing PtExampleSelector.\n",
    "        return FewShotPromptTemplate(\n",
    "            example_selector=self.selector,\n",
    "            example_prompt=example_prompt,\n",
    "            suffix=suffix,\n",
    "            input_variables=input_variables,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b78a75-d7a2-4e35-b024-2334e8d7a657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
